apiVersion: scaffolder.backstage.io/v1beta3
kind: Template
metadata:
  name: cdp-aws-workload-spark-template-skeleton
  title: Workload CDP Spark Template (Skeleton)
  description: Create a repository containing the definition of a CDP Spark Workload
  mesh:
    icon: https://upload.wikimedia.org/wikipedia/commons/thumb/f/f3/Apache_Spark_logo.svg/1200px-Apache_Spark_logo.svg.png
  annotations:
    backstage.io/techdocs-ref: dir:.
  tags:
    - aws
    - cdp
    - spark
    - workload
spec:
  generates: componenttype:default/workload
  owner: agilelab
  type: workload
  parameters:
    - title: Component basic information
      required:
        - name
        - domain
        - dataproduct
        - description
      properties:
        name:
          title: Name
          type: string
          description: Required name used for display purposes
          ui:field: EntityNamePicker
          default: Spark CDP Workload
          ui:options:
            allowArbitraryValues: true
        description:
          title: Description
          type: string
          description: Help others understand what this Workload is for
        domain:
          title: Domain
          type: string
          description: Domain of the Data Product this Workload belongs to
          ui:field: EntityPicker
          ui:options:
            allowArbitraryValues: false
            allowedKinds:
              - Domain
        dataproduct:
          title: Data Product
          type: string
          description: Data Product this Workload belongs to
          ui:field: EntityPicker
          ui:filter:
            - fieldName: domain
              entityPath: spec.domain
          ui:options:
            allowArbitraryValues: false
            allowedKinds:
              - System
        identifier:
          title: Identifier
          type: string
          description: A unique identifier for the entity inside the domain. It will not
            be editable after creation and is expected to be a string that is
            sequences of [a-zA-Z] separated by any of [-_]. An example could be
            'finance-customer'
          ui:field: ComponentIdentifierPicker
          ui:options:
            allowArbitraryValues: false
        developmentGroup:
          title: DevelopmentGroup
          type: string
          description: Data Product development group
          ui:field: EntitySelectionPicker
          ui:fieldName: dataproduct
          ui:property: spec.owner
          ui:options:
            allowArbitraryValues: false
        dependsOn:
          title: Depends on
          type: array
          default: []
          items:
            type: string
            ui:field: EntityComponentsPicker
            ui:fieldName: dataproduct
            ui:options:
              allowArbitraryValues: false
          description: A Workload could depend on other components
        readsFrom:
          title: Reads from
          type: array
          default: []
          items:
            type: string
            ui:field: ReadsFromPicker
          description: This is filled only for DataPipeline workloads and it represents
            the list of output ports or external systems that is reading
        domainName:
          type: string
          ui:field: EntitySelectionPicker
          ui:fieldName: domain
          ui:property: spec.mesh.name
          ui:options:
            allowArbitraryValues: false
          ui:widget: hidden
        dataproductName:
          type: string
          ui:field: EntitySelectionPicker
          ui:fieldName: dataproduct
          ui:property: spec.mesh.name
          ui:options:
            allowArbitraryValues: false
          ui:widget: hidden
    - title: Spark infrastructure details
      required:
        - service
        - cluster
        - bucket
        - jobName
      properties:
        service:
          title: CDE Service
          type: string
          description: Name of the CDE Service
        cluster:
          title: CDE Virtual Cluster
          type: string
          description: Name of the CDE Virtual Cluster
        bucket:
          title: Artifact bucket
          type: string
          description: S3 Bucket name where spark artifacts will be stored
        jobName:
          title: Job name
          type: string
          description: Spark job name must be formatted as
            $DpDomain-$DpName-$DpMajorVersion-$WorkloadName-$Environment and
            must contains only characters in the range [a-zA-Z0-9-_]. Any not
            allowed characters in $DpDomain, $DpName, $DpMajorVersion or
            $Environment must be substituted with \"-\"
    - title: Spark job details
      properties:
        driverCores:
          title: Driver Cores
          type: integer
          description: Number of Driver Cores (If specified must be a positive integer)
        driverMemory:
          title: Driver Memory
          type: string
          description: Driver Memory (If specified must be a positive integer followed by
            'g' e.g. 2g)
        executorCores:
          title: Executor Cores
          type: integer
          description: Number of Executor Cores (If specified must be a positive integer)
        executorMemory:
          title: Executor Memory
          type: string
          description: Executor Memory (If specified must be a positive integer followed
            by 'g' e.g. 2g)
        numExecutors:
          title: Number of executors
          type: integer
          description: Number of executors (If specified must be a positive integer)
    - title: Spark job scheduling
      properties:
        enableScheduling:
          type: boolean
          title: Enable scheduling
          default: false
      allOf:
        - if:
            properties:
              enableScheduling:
                const: true
          then:
            properties:
              cronExpression:
                title: Cron expression
                type: string
                description: "Cron expression (format: Min Hour DayOfMonth Month DayOfWeek)"
              startDate:
                title: Start Date
                type: string
                format: date-time
              endDate:
                title: End Date
                type: string
                format: date-time
            required:
              - cronExpression
              - startDate
              - endDate
          else:
            properties: {}
  steps:
    - id: template
      name: Fetch Skeleton + Template
      action: fetch:template
      input:
        url: ./skeleton
        targetPath: ${{ parameters.rootDirectory }}
        values:
          name: ${{ parameters.name }}
          domainName: ${{ parameters.domainName }}
          dataproductName: ${{ parameters.dataproductName }}
          description: ${{ parameters.description }}
          domain: ${{ parameters.domain }}
          dataproduct: ${{ parameters.dataproduct }}
          identifier: ${{ parameters.identifier }}
          developmentGroup: ${{ parameters.developmentGroup }}
          dependsOn: ${{ parameters.dependsOn }}
          readsFrom: ${{ parameters.readsFrom }}
          service: ${{ parameters.service }}
          cluster: ${{ parameters.cluster }}
          bucket: ${{ parameters.bucket }}
          jobName: ${{ parameters.jobName }}
          driverCores: ${{ parameters.driverCores }}
          driverMemory: ${{ parameters.driverMemory }}
          executorCores: ${{ parameters.executorCores }}
          executorMemory: ${{ parameters.executorMemory }}
          numExecutors: ${{ parameters.numExecutors }}
          enableScheduling: ${{ parameters.enableScheduling }}
          cronExpression: ${{ parameters.cronExpression }}
          startDate: ${{ parameters.startDate | truncate(19, true, "Z") }}
          endDate: ${{ parameters.endDate | truncate(19, true, "Z") }}
          useCaseTemplateId: urn:dmb:utm:spark-workload-template:0.0.0
          infrastructureTemplateId: urn:dmb:itm:cdp-aws-workload-spark-provisioner:0
          useCaseTemplateVersion: 0.0.0
          destination: gitlab.com?owner=AgileDMBSandbox%2F${{orgname}}%2Fmesh.repository%2F${{
            parameters.domain | replace(r/domain:| |-/, "") }}%2F${{
            parameters.dataproduct.split(".")[1] | replace(r/ |-/g, "")
            }}&repo=${{ parameters.name.split(" ") | join("") | lower }}
          displayName: ${{ parameters.displayName }}
          owner: AgileDMBSandbox%2F${{orgname}}%2Fmesh.repository%2F${{ parameters.domain
            | replace(r/domain:| |-/, "") }}%2F${{
            parameters.dataproduct.split(".")[1] | replace(r/ |-/g, "") }}
          repo: ${{ parameters.name.split(" ") | join("") | lower }}
    - id: publish
      name: Publish
      action: witboostMeshComponent:publish:gitlab
      input:
        allowedHosts:
          - gitlab.com
        description: This is ${{ parameters.name }}
        repoUrl: gitlab.com?owner=simone.pusceddu&repo=${{ parameters.name.split(" ") | join("") | lower }}
        rootDirectory: ${{ parameters.rootDirectory }}
        dataproduct: ${{ parameters.dataproduct }}
    - id: register
      name: Register
      action: catalog:register
      input:
        repoContentsUrl: ${{ steps.publish.output.repoContentsUrl }}
        catalogInfoPath: /catalog-info.yaml
  output:
    links:
      - title: Repository
        url: ${{ steps.publish.output.remoteUrl }}
      - title: Open in catalog
        icon: catalog
        entityRef: ${{ steps.register.output.entityRef }}
